{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 : Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you have to use the logistic regression technique you learned in the week 3 of the prescribed course. You have to use numpy to complete the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import other the libraries here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import sklearn.linear_model as skl\n",
    "import sklearn as sk\n",
    "import cv2 as cv\n",
    "import random "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define these functions here:\n",
    "- Sigmoid function: `def sigmoid(x):`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cost function: `def cost_fn(x,y,theta):` (refer to the course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thx(theta, x):\n",
    "    temp = 0\n",
    "    for i in range(0,len(x)):\n",
    "        temp += theta[i]*x[i]\n",
    "    return temp\n",
    "\n",
    "def cost_fn(x, y, theta):\n",
    "    sum = 0\n",
    "    m=len(y)\n",
    "    for i in range(m):\n",
    "        sum += -(y[i]*(np.log(sigmoid(thx(theta, x[i])))) + (1 - y[i])*(np.log(1 - sigmoid(thx(theta, x[i])))))*1/m\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient descent: `def gradient_descent(X, y, theta, learning_rate=1, iters):`\n",
    "\n",
    "$\\frac{\\partial J}{\\partial \\theta} = \\frac{1}{m} \\Sigma_{i=1}^m ((h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)})$\n",
    "\n",
    "$\\theta_{j+1}^{(i)} = \\theta_j^{(i)} - \\frac{1}{m} \\Sigma_{i=1}^m ((h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)})$\n",
    "\n",
    "Since these are for each element of your matrix. The final expression will be: (if using matrices)\n",
    "$\\theta_{j+1} = \\theta_j - \\frac{1}{m} \\Sigma_{i=1}^m ((h_\\theta(x)-y)x_j)$\n",
    "\n",
    "You have to initialise $\\theta$ and update it at each iteration according to this gradient descent equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, theta, num_iter, learning_rate = 1):\n",
    "    \n",
    "    a = learning_rate\n",
    "    m = len(y)\n",
    "    cost=np.array([])\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        sum = np.zeros(len(theta))\n",
    "        for j in range(0,m):\n",
    "            sum += (1/m)*(sigmoid(thx(theta, x[j])) - y[j])*x[j]\n",
    "        \n",
    "        theta = theta - a*sum\n",
    "        cost = np.append(cost, cost_fn(x, y, theta))\n",
    "        \n",
    "    return theta, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predict: `def predict(X, y, theta, learning_rate=1, iters)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mclass(y):\n",
    "    \n",
    "    mdata = np.array([])\n",
    "    for i in range(10):\n",
    "        temp = np.array([])\n",
    "        for j in range(5000):\n",
    "            if(y[j] == i):\n",
    "                temp = np.append(temp, 1)\n",
    "            else:\n",
    "                temp = np.append(temp, 0)\n",
    "        \n",
    "        mdata = np.append(mdata,temp)\n",
    "   \n",
    "    return mdata.reshape(10,5000)\n",
    "    \n",
    "\n",
    "def predict(x, y, theta, num_iter, learning_rate=1):\n",
    "    \n",
    "    y = mclass(y)\n",
    "    mod_theta = np.array([])\n",
    "    cost = np.array([])\n",
    "    \n",
    "    for i in range(10):\n",
    "        temp_t, temp_c = gradient_descent(x, y[i], theta, num_iter, learning_rate)\n",
    "        mod_theta = np.append(mod_theta, temp_t)\n",
    "        cost = np.append(cost, temp_c)\n",
    "    \n",
    "    mod_theta = mod_theta.reshape(10,401)\n",
    "    cost = cost.reshape(10, num_iter)\n",
    "    \n",
    "    return mod_theta, cost\n",
    "\n",
    "def prob(x, y, theta, num_iter, learning_rate = 1):\n",
    "    \n",
    "    mod_theta, cost = predict(x, y, theta, num_iter, learning_rate)\n",
    "    pdata = np.array([])\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        for j in range(10):\n",
    "            temp = sigmoid(thx(mod_theta[j], x[i]))\n",
    "            pdata = np.append(pdata, temp)\n",
    "    \n",
    "    pdata_reshape = pdata.reshape(5000,10)\n",
    "    prediction = np.array([])\n",
    "    \n",
    "    for i in range(5000):\n",
    "        prediction = np.append(prediction, np.argmax(pdata_reshape[i]))\n",
    "    \n",
    "    return prediction, pdata_reshape, cost, mod_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNSIT data here\n",
    "\n",
    "There are two file, X.csv and y.csv.\n",
    "You have to load these csv files (read about csv in python) and store them in python variables. \n",
    "There are 5000 images, each line in X.csv is an image (pixels of image of size 20x20 are concatenated to size 400x1) and each line is y.csv is the label of that image (label in n-th line in y.csv corresponds to image in n-th line in X.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#initializations\n",
    "x = np.loadtxt('X.csv', delimiter = ',')\n",
    "y = np.loadtxt('y.csv')\n",
    "theta = np.zeros(len(x[0]) + 1)\n",
    "num_iter = 10\n",
    "#print(x)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your task is to:\n",
    "1. Reshape these to 20x20 and show any 5 of them (random) here. \n",
    "2. For regression, you have to use the 400x1 data only. (X will be a 5000x400 matrix and y will be a 1x400 matrix)\n",
    "3. Get you prediction and compare it with the labels in y\n",
    "4. Calculate the error %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_reshaped = (x.flatten()).reshape(5000,20,20)\n",
    "\n",
    "a = x_reshaped[random.randint(0,4995)]\n",
    "for i in range(9):\n",
    "    a = np.hstack((a, x_reshaped[random.randint(0,5000)]))\n",
    "cv.imshow(\"Random_image\",a)\n",
    "k=cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.zeros((5000,1))\n",
    "for i in range(5000):\n",
    "    e[i][0] = 1\n",
    "mod_x = np.hstack((e,x))\n",
    "\n",
    "prediction, pdata, cost, mod_theta = prob(mod_x, y, theta, num_iter, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of accurate predictions =  4200\n",
      "Percent error [ 8.28709531 11.76497245 91.69788505 ... 65.78423401 76.35598146\n",
      " 82.90295562]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(5000):\n",
    "    if(prediction[i] == y[i]):\n",
    "        count += 1\n",
    "print(\"Number of accurate predictions = \", count)\n",
    "\n",
    "error=np.array([])\n",
    "for i in range(5000):\n",
    "    error = np.append(error, 1 - np.max(pdata[i]))\n",
    "error = error*100\n",
    "print(\"Percent error\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the confusion matrix here and show it here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:  \n",
      "\n",
      "[[476   1   1   2   1   0  13   0   6   0]\n",
      " [  0 481   1   1   0   2   2   0  13   0]\n",
      " [ 10  19 397  15   9   1  18   6  22   3]\n",
      " [  3   7  19 411   0  13   4   7  27   9]\n",
      " [  2   7   5   1 427   0  14   3   8  33]\n",
      " [ 19  15   7  72  17 305  16   1  34  14]\n",
      " [  9  13  10   0   4   3 457   1   3   0]\n",
      " [ 10  21   6   1  13   0   0 434   1  14]\n",
      " [  2  11  10  27   3   7   7   2 419  12]\n",
      " [ 10   7   5   7  34   5   2  25  12 393]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix: \", '\\n')\n",
    "print(sk.metrics.confusion_matrix(y,prediction,labels=[0,1,2,3,4,5,6,7,8,9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus task: \n",
    "Use [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) to perform logistic regression (just a single function which will handle all your task :P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bhavy\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "regression = skl.LogisticRegression().fit(x,y)\n",
    "sk_prediction=log_reg.predict(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
